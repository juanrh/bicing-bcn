package org.collprod.bicingbcn.ingestion;

import java.util.HashMap;
import java.util.Map;

import org.apache.commons.configuration.Configuration;
import org.apache.commons.configuration.ConfigurationException;
import org.collprod.bicingbcn.ingestion.tsparser.TimeStampParser;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import backtype.storm.task.OutputCollector;
import backtype.storm.task.TopologyContext;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseRichBolt;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Tuple;
import backtype.storm.tuple.Values;

import com.atlassian.fugue.Either;

public class TimestampParserBolt extends BaseRichBolt {

		// Auto generated by Eclipse
	private static final long serialVersionUID = 9174174434118277771L;
	
	private final static Logger LOGGER = LoggerFactory.getLogger(TimestampParserBolt.class);
	
	public static final String TIMESTAMP_FIELD = "TIMESTAMP_FIELD";
	
	/**
	 * For each data source stores either the class name for a TimeStampParser (left), or 
	 * a TimeStampParser object (right) 
	 * */
	private Map<String, Either<String, TimeStampParser>> timestampParsers;
	/**
	 * Storm collector to emit tuples
	 * */
	private OutputCollector collector;
	
	@Override
	public void prepare(Map stormConf, TopologyContext context,
			OutputCollector collector) {
		this.collector = collector;
		this.timestampParsers = new HashMap<String, Either<String, TimeStampParser>>();
		try {
			Map<String, Configuration> datasourcesConfigurations = 
					IngestionTopology.deserializeConfigurations((Map<String, String>) stormConf.get(IngestionTopology.DATASOURCE_CONF_KEY));
			for (Map.Entry<String, Configuration> datasourceConfig : datasourcesConfigurations.entrySet()) {
				Either<String, TimeStampParser> newTimestampParser = Either.left(datasourceConfig.getValue().getString("timestamp_parser_class"));
				this.timestampParsers.put(datasourceConfig.getKey(), newTimestampParser);
			}
			
		} catch (ConfigurationException ce) {
			LOGGER.error("Error parsing datasource configurations: " + ce.getMessage());
			throw new RuntimeException(ce);
		}
	}
	
	private TimeStampParser getParser(String datasource) {
		Either<String, TimeStampParser> timestampParser = this.timestampParsers.get(datasource);
		if (timestampParser.isLeft()) {
			try {
				timestampParser =  Either.right((TimeStampParser) Class.forName(timestampParser.left().get()).newInstance());
			} catch (InstantiationException ie) {
				LOGGER.error("Error creating TimeStampParser for data source " + datasource 
						+ ": " + ie.getMessage());
				throw new RuntimeException(ie);
			} catch (IllegalAccessException iae) {
				LOGGER.error("Error creating TimeStampParser for data source " + datasource 
						+ ": " + iae.getMessage());
				throw new RuntimeException(iae);
			} catch (ClassNotFoundException cnfe) {
				LOGGER.error("Error creating TimeStampParser for data source " + datasource 
						+ ": " + cnfe.getMessage());
				throw new RuntimeException(cnfe);
			}
		} 
		return timestampParser.right().get();
	}

	@Override
	public void execute(Tuple inputTuple) {
		/* Create a new parser if needed. If this is too slow we
		then a timeout will be raised and the warranteed processing
		mechanism will replay the tuple, but now the parser will be ready 
		*/
		TimeStampParser timestampParser = getParser(inputTuple.getStringByField(RestIngestionSpout.DATASOURCE_ID));
		String data = inputTuple.getStringByField(RestIngestionSpout.CONTENT_FIELD);
		Long timestamp = timestampParser.apply(data);
		if (timestamp != null) {
			this.collector.emit(new Values(timestamp, data));
		}
		else {
			this.collector.fail(inputTuple);
		}
	}

	@Override
	public void declareOutputFields(OutputFieldsDeclarer declarer) {
		declarer.declare(new Fields(TIMESTAMP_FIELD, RestIngestionSpout.CONTENT_FIELD));
	}
}
