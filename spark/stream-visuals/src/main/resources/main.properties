# General configuration
# Needs more than 1 process as "the way Spark Streaming works is that it assigns a core to the
# data receiver, and so if you run the program with only one core (i.e., with local or local[1]),
# then it wont have resources to process data along with receiving it" http://apache-spark-user-list.1001560.n3.nabble.com/streaming-questions-td3281.html 
spark.master=local[4]
# spark.master=yarn-client # for Yarn
spark.app_name=heatmap
spark.batch_duration=1000
# For local mode
spark.checkpoint_dir=/home/cloudera/bicing/streaming_checkpoints
# For distributed mode, doesn't work in local mode for a client ipc version mismatch. Although followed http://spark.apache.org/docs/latest/hadoop-third-party-distributions.html, 
# I get http://qnalist.com/questions/4957822/hdfs-server-client-ipc-version-mismatch-while-trying-to-access-hdfs-files-using-spark-0-9-1, http://comments.gmane.org/gmane.comp.lang.scala.spark.user/106
# spark.checkpoint_dir=hdfs://localhost:8020/user/cloudera/bicing/streaming_checkpoints
# Kafka resources
kafka.zookeeper.quorum=localhost:2181
kafka.groupid=0
#   FIXME: topic for testing
kafka.bicing_topic=test_bicing_station_data
kafka.bicing_topic_threads=2
# CartoDB: API key is in a separate file
cartodb.sql_api.scheme=http
cartodb.sql_api.host=juanrh.cartodb.com
cartodb.sql_api.path=/api/v2/sql
# Phoenix configuration
phoenix.jdbc_driver=org.apache.phoenix.jdbc.PhoenixDriver
phoenix.db_url=jdbc:phoenix:localhost
